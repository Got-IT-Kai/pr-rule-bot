# Dockerfile for Ollama with pre-loaded Qwen2.5-Coder model
# License: Apache 2.0 (Qwen2.5-Coder 7B)
# This image includes the Qwen2.5-Coder model to avoid downloading it during CI runs

FROM ollama/ollama:latest

# Set environment variable for model (3b - balanced for code review performance and CI speed)
ENV OLLAMA_MODEL=qwen2.5-coder:3b

# Start Ollama service in background, pull the model, then stop gracefully
RUN ollama serve & \
    OLLAMA_PID=$! && \
    sleep 5 && \
    ollama pull ${OLLAMA_MODEL} && \
    sleep 2 && \
    kill -TERM $OLLAMA_PID && \
    sleep 2 && \
    wait $OLLAMA_PID 2>/dev/null || true

# Expose Ollama API port
EXPOSE 11434

# Startã…‡ Ollama service when container runs
ENTRYPOINT ["/bin/ollama"]
CMD ["serve"]
